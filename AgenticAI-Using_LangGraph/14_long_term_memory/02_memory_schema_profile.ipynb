{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33b441ff",
   "metadata": {},
   "source": [
    "# Chatbot with Profile Schema \n",
    "\n",
    "## Review\n",
    "\n",
    "We introduced the [LangGraph Memory Store](https://reference.langchain.com/python/langgraph/store/?h=basestor#langgraph.store.base.BaseStore) as a way to save and retrieve long-term memories.\n",
    "\n",
    "We built a simple chatbot that uses both `short-term (within-thread)` and `long-term (across-thread)` memory.\n",
    "\n",
    "It saved long-term [semantic memory](https://docs.langchain.com/oss/python/concepts/memory#semantic-memory) (facts about the user) [\"in the hot path\"](https://docs.langchain.com/oss/python/concepts/memory#writing-memories), as the user is chatting with it.\n",
    "\n",
    "## Goals\n",
    "\n",
    "Our chatbot saved memories as a string. In practice, we often want memories to have a structure. \n",
    " \n",
    "For example, memories can be a [single, continuously updated schema](https://docs.langchain.com/oss/python/concepts/memory#profile). \n",
    " \n",
    "In our case, we want this to be a single user profile.\n",
    " \n",
    "We'll extend our chatbot to save semantic memories to a single [user profile](https://docs.langchain.com/oss/python/concepts/memory#profile). \n",
    "\n",
    "We'll also introduce a library, [Trustcall](https://github.com/hinthornw/trustcall), to update this schema with new information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cbaa7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from typing import TypedDict, List, List, Optional\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "from pydantic import BaseModel, Field, ValidationError\n",
    "from langchain_openai import ChatOpenAI\n",
    "from IPython.display import Image, display\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, MessagesState, START, END\n",
    "from langgraph.store.base import BaseStore\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "from langchain_core.runnables.config import RunnableConfig\n",
    "from trustcall import create_extractor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe4d4f5",
   "metadata": {},
   "source": [
    "## Defining a user profile schema\n",
    "\n",
    "Python has many different types for [structured data](https://docs.langchain.com/oss/python/langchain/models#structured-outputs), such as TypedDict, Dictionaries, JSON, and [Pydantic](https://docs.pydantic.dev/latest/). \n",
    "\n",
    "Let's start by using TypedDict to define a user profile schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07a42c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserProfile(BaseModel):\n",
    "    \"\"\"User profile schema with typed fields\"\"\"\n",
    "\n",
    "    user_name: str\n",
    "    interests: List[str]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c15dc9",
   "metadata": {},
   "source": [
    "## Saving a schema to the store\n",
    "\n",
    "The  [LangGraph Store](https://reference.langchain.com/python/langgraph/store/?h=basestor#langgraph.store.base.BaseStore) accepts any Python dictionary as the `value`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bd47638",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UserProfile(user_name='Umer', interests=['Being lonely', 'woundering'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_profile = UserProfile(\n",
    "    user_name=\"Umer\",\n",
    "    interests=[\"Being lonely\", \"woundering\"]\n",
    ")\n",
    "user_profile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f572db95",
   "metadata": {},
   "source": [
    "We use the [put](https://reference.langchain.com/python/langgraph/store/?h=basestor#langgraph.store.base.BaseStore.put) method to save the TypedDict to the store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a16288df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the in-memory store\n",
    "in_memory_store = InMemoryStore()\n",
    "\n",
    "# Namespace for the memory to save\n",
    "user_id = \"1\"\n",
    "namespace_for_memory = (user_id, \"memory\")\n",
    "\n",
    "# Save a memory to namespace as key and value\n",
    "key = \"user_profile\"\n",
    "\n",
    "in_memory_store.put(namespace_for_memory, key, user_profile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18eaff2",
   "metadata": {},
   "source": [
    "We use [search](https://reference.langchain.com/python/langgraph/store/?h=basestor#langgraph.store.base.BaseStore.search) to retrieve objects from the store by namespace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d77d11df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'namespace': ['1', 'memory'], 'key': 'user_profile', 'value': UserProfile(user_name='Umer', interests=['Being lonely', 'woundering']), 'created_at': '2026-01-05T15:00:09.062080+00:00', 'updated_at': '2026-01-05T15:00:09.062080+00:00', 'score': None}\n"
     ]
    }
   ],
   "source": [
    "for m in in_memory_store.search(namespace_for_memory):\n",
    "    print(m.dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f83eb12",
   "metadata": {},
   "source": [
    "We can also use [get](https://reference.langchain.com/python/langgraph/store/?h=basestor#langgraph.store.base.BaseStore.get) to retrieve a specific object by namespace and key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0114c9bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UserProfile(user_name='Umer', interests=['Being lonely', 'woundering'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profile = in_memory_store.get(namespace_for_memory, \"user_profile\")\n",
    "profile.value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfb74a8",
   "metadata": {},
   "source": [
    "## Chatbot with profile schema\n",
    "\n",
    "Now we know how to specify a schema for the memories and save it to the store.\n",
    "\n",
    "Now, how do we actually *create* memories with this particular schema?\n",
    "\n",
    "In our chatbot, we [want to create memories from a user chat](https://docs.langchain.com/oss/python/concepts/memory#profile). \n",
    "\n",
    "This is where the concept of [structured outputs](https://docs.langchain.com/oss/python/langchain/models#structured-outputs) is useful. \n",
    "\n",
    "LangChain's [chat model](https://docs.langchain.com/oss/python/langchain/models) interface has a [`with_structured_output`](https://docs.langchain.com/oss/python/langchain/models#structured-outputs) method to enforce structured output.\n",
    "\n",
    "This is useful when we want to enforce that the output conforms to a schema, and it parses the output for us."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a7ba2d",
   "metadata": {},
   "source": [
    "Let's pass the `UserProfile` schema we created to the `with_structured_output` method.\n",
    "\n",
    "We can then invoke the chat model with a list of [messages](https://docs.langchain.com/oss/python/langchain/messages) and get a structured output that conforms to our schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8d8526c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "\n",
    "# Bind schema to model\n",
    "model_with_structure = model.with_structured_output(UserProfile)\n",
    "\n",
    "response = model_with_structure.invoke([HumanMessage(content=\"My name is umer, I live in Karachi with my family. I am single.\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "096d0905",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UserProfile(user_name='Umer', interests=['Technology', 'Travel', 'Food', 'Movies', 'Music'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91db22b5",
   "metadata": {},
   "source": [
    "Now, let's use this with our chatbot.\n",
    "\n",
    "This only requires minor changes to the `write_memory` function. \n",
    "\n",
    "We use `model_with_structure`, as defined above, to produce a profile that matches our schema. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f3f06d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chatbot instruction\n",
    "MODEL_SYSTEM_MESSAGE = \"\"\"\n",
    "    You are a helpful assistant with memory that provides information about the user. \n",
    "    If you have memory for this user, use it to personalize your responses.\n",
    "    Here is the memory (it may be empty): {memory}\n",
    "    \"\"\"\n",
    "\n",
    "# Create new memory from the chat history and any existing memory\n",
    "CREATE_MEMORY_INSTRUCTION = \"\"\"\n",
    "    Create or update a user profile memory based on the user's chat history. \n",
    "    This will be saved for long-term memory. If there is an existing memory, simply update it. \n",
    "    Here is the existing memory (it may be empty): {memory}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fb8c6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentic-ai-tutorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
