{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b7114f7-abee-4b4f-a9bf-fbd7ac553357",
   "metadata": {},
   "source": [
    "**Load environmental variables**: See \"Getting setup\" in the first modele.  `dotenv` [docs](https://pypi.org/project/python-dotenv/) will look for `.env`. If it finds it, it will load environmental variables from there, overriding any variables in the current shell. If it is not found, variables currently in the shell are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23e3c17-6676-4b93-9662-8df5d8542d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings, os\n",
    "\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=\"LangSmith now uses UUID v7\", \n",
    "    category=UserWarning,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38cb48f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# automatically reload all modules before executing new code. The captures changes in local packages.\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "09dd8911",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Create Agent  - Prebuilt\n",
    "\n",
    "<img src=\"./assets/agent_header.png\" width=\"800\" style=\"display:block; margin-left:0;\">\n",
    "\n",
    "In this course, you're going to build a [Deep Agent](https://blog.langchain.com/deep-agents/). We'll build this on top of LangChains's 'pre-built' agent abstraction, which simplifies the code significantly. In this lesson, you'll learn about the pre-built ReAct agent. Here's what you will learn:\n",
    "- What is a ReAct Agent\n",
    "- The capabilities of our implementation and where to find out more.\n",
    "    - Build an agent with tools\n",
    "    - The graph, state and messages\n",
    "    - Access and modify state with tools\n",
    "    - <span style=\"font-size:0.8em;\">ü™ù</span> hooks! and structured responses\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96d31dc-3ffb-4afb-85ef-5e10f9a85f24",
   "metadata": {},
   "source": [
    "### What is a ReAct agent \n",
    "\n",
    "\n",
    "<img src=\"./assets/agent.png\"\n",
    "     style=\"float:left; max-width:300px; height:auto; margin:0 1rem 0.5rem 0;\">\n",
    "<div style=\"max-width: 1250px;\">\n",
    "    \n",
    "You will be using LangChain's open-source `create_agent` ([see here](https://docs.langchain.com/oss/python/langchain/agents)) abstraction. A **ReAct agent** is an AI agent that uses the \"Reasoning and Acting\" (ReAct) framework to combine chain-of-thought (CoT) reasoning with external tool use. It was made popular by the paper [ReAct: Synergizing Reasoning and Acting in Language Models](https://arxiv.org/abs/2210.03629). \n",
    "\n",
    "This agent consists of three components: a large language model (LLM), a set of tools it can use, and a prompt that provides instructions.\n",
    "\n",
    "The LLM operates in a loop. In each iteration, it examines its context, which includes a list of available tools; It decides if it needs to call a tool. It selects a tool to invoke, forms the tool call. This is sent to a tool node for execution. The tool node executes the tool(s), and sends the results (observations) back to the LLM. The LLM receives the observations(s) and uses that observation to inform the next action. The loop continues until a stopping condition is met ‚Äî typically when the agent decides it no longer needs to call more tools.\n",
    "</div>\n",
    "\n",
    "<div style=\"clear:both;\"></div>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "038dca59",
   "metadata": {},
   "source": [
    "### Key capabilities of `create_agent`\n",
    "\n",
    "Here are some of the features that come with the `create_agent` abstraction. We won't make use of them all in this course, but it does motivate the use of `create_agent` to build our course.:\n",
    "\n",
    "- [Memory integration](../how-tos/memory/add-memory.md): Native support for _short-term_ (session-based) and _long-term_ (persistent across sessions) memory, enabling stateful behaviors in chatbots and assistants.\n",
    "- [Human-in-the-loop control](../concepts/human_in_the_loop.md): Execution can pause _indefinitely_ to await human feedback‚Äîunlike websocket-based solutions limited to real-time interaction. This enables asynchronous approval, correction, or intervention at any point in the workflow.\n",
    "- [Streaming support](../how-tos/streaming.md): Real-time streaming of agent state, model tokens, tool outputs, or combined streams.\n",
    "- [Deployment tooling](../tutorials/langgraph-platform/local-server.md): Includes infrastructure-free deployment tools. [**LangGraph Platform**](https://langchain-ai.github.io/langgraph/concepts/langgraph_platform/) supports testing, debugging, and deployment.\n",
    "  - [Studio](https://langchain-ai.github.io/langgraph/concepts/langgraph_studio/): A visual IDE for inspecting and debugging workflows.\n",
    "  - [LangSmith](https://smith.langchain.com/): A tracing and evaluation tool.\n",
    "  - Supports multiple [deployment options](https://langchain-ai.github.io/langgraph/concepts/deployment_options.md) for production.\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c629549-8161-4665-b536-d27038861a79",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #fff3b0; padding: 10px; border-radius: 4px;\">\n",
    "<b>Note:</b>  \n",
    "The <code>create_react_agent</code> was moved from the LangGraph library to the LangChain library and renamed to <code>create_agent</code> in the 1.0 code release post-filming. The video and notebooks in this lesson have been updated to reflect this; however, in the remaining lessons, only the notebooks are updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4527ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, List, Literal, Union\n",
    "\n",
    "from langchain_core.messages import ToolMessage\n",
    "from langchain_core.tools import InjectedToolCallId, tool\n",
    "from langgraph.prebuilt import InjectedState\n",
    "from langgraph.types import Command\n",
    "from IPython.display import Image, display, JSON\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain.agents import create_agent \n",
    "from utils import format_messages\n",
    "from langchain.agents import AgentState\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee33aed8-3c03-4fe3-b2ba-ae448ad86111",
   "metadata": {},
   "source": [
    "#### Build an agent with tools\n",
    "\n",
    "Let's start by creating an agent with a simple calculator tool to get started. Once you see how things are put together, we'll go over more details.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf73e64-eb00-4d13-89cb-5857e4861f34",
   "metadata": {},
   "source": [
    "###  The graph, state and messages\n",
    "You'll run the agent in a moment, but let's dig into the graph a little bit. \n",
    " If you would like to try building a simple version of this yourself, you can check out [Foundation: Introduction to LangGraph, Module 1, Lesson 6, Agent](https://academy.langchain.com/courses/take/intro-to-langgraph/lessons/58239232-lesson-6-agent).\n",
    "\n",
    "**Defining the Agent**: When you define an agent as you did above, you provide: the model, one or more tools, a \"system\" prompt, and state schema which defaults to <a href=\"https://github.com/langchain-ai/langgraph/blob/e365b2b8bd695e03d758b19ff109152b2e342a87/libs/prebuilt/langgraph/prebuilt/chat_agent_executor.py#L62-L69\">\n",
    "  <code style=\"color:#0366d6;\">AgentState</code>\n",
    "</a> which is primarily a list of messages. ([Call details here.](https://langchain-ai.github.io/langgraph/reference/agents/#langgraph.prebuilt.chat_agent_executor.create_react_agent))\n",
    "Under the hood, this is defining and compiling the LangGraph graph shown above. An important detail is that the tools node is another pre-built item, a `ToolNode`, described [here](https://github.com/langchain-ai/langgraph/blob/e365b2b8bd695e03d758b19ff109152b2e342a87/libs/prebuilt/langgraph/prebuilt/tool_node.py#L239-L293). A tool node will run all the tools identified in the message from the LLM and return the results.\n",
    "\n",
    "**Invoking the Agent:** \n",
    "Let's call the agent and see what we get!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b437e65-8b4f-48ec-9ab5-b988fe6b536d",
   "metadata": {},
   "source": [
    "**Invoking the Agent:** \n",
    "A sequence diagram is a great way to look at what happens when the model is invoked.\n",
    "\n",
    "<div style=\"display:none\">\n",
    "    the mermaid code is saved here for future\n",
    "```mermaid\n",
    "sequenceDiagram\n",
    "    participant U as User\n",
    "    participant A as LLM\n",
    "    participant T as Tools\n",
    "    Note over A: System message<br/>\"You are a helpful assistant...\"\n",
    "    U->>A: Initial input,<br/>\"What is 3.1 * 4.2?\"\n",
    "    loop while tool_calls present\n",
    "        A->>T: AIMessage(id=\"call_123\", tool_calls=[...])\n",
    "        T-->>A: ToolMessage(tool_call_id=\"call_123\", content=\"xx\")\n",
    "    end\n",
    "    A->>U: Return final state\n",
    "```\n",
    "</div> \n",
    "\n",
    "<img src=\"./assets/agent_sequence_diagram.png\"\n",
    "     style=\"float:left; max-width:500px; height:auto; margin:0 1rem 0.5rem 0;\">\n",
    "<div style=\"max-width: 1100px;\">\n",
    "In our example, the user input is \"What is 3.1 * 4.2?\". This, combined with the system prompt and tool descriptions, is sent to the LLM.  \n",
    "<br/>\n",
    "<p style=\"margin-bottom:0; margin-top:5px;\">The LLM decides that the calculator tool should be called. <br/> It adds an `AIMessage` to `messages`:</p>\n",
    "<pre style=\"font-size:0.85em; margin-top:5px; margin-bottom:0;\">\n",
    "<code class=\"language-python\">AIMessage(\n",
    "    content=\"\",\n",
    "    tool_calls=[{\"id\": \"call_123\",\n",
    "                 \"name\": \"calculator\",\n",
    "                 \"args\": {\"a\": 3.1, \"b\": 4.2, \"operation\": \"multiply\"}}])</code></pre>   \n",
    "</code></pre>\n",
    "<br/>\n",
    "<p style=\"margin-bottom:0;\">The tool node receives the AIMessage and processes all the tool calls. It tracks the tool_call_ids. It responds with a ToolMessage in `messages`: </p>\n",
    "<pre style=\"font-size:0.85em; margin-top:5px; margin-bottom:10px;\">\n",
    "<code class=\"language-python\">ToolMessage(\n",
    "    content=\"13.02\",         # The result of the tool execution.\n",
    "    tool_call_id=\"call_123\")  # Matches the id from the AIMessage.tool_calls\n",
    "</code></pre>\n",
    "The LLM examines the response in `messages`, decides it is done, and forms an `AIMessage` to the user.\n",
    "\n",
    "</div>\n",
    "\n",
    "<div style=\"clear:both;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784297e4-a617-41f6-a300-9ff06598c023",
   "metadata": {},
   "source": [
    "Let's look at a prior [trace in LangSmith](https://smith.langchain.com/public/3d2062e3-8713-4510-a797-801abe44d1f7/r). Here are some things to notice:\n",
    "- In the metadata of the call to the LLM, you will see the 'calculator' tool description.\n",
    "- The response from the model is a tool call with the arguments\n",
    "- In the final call to the LLM, notice the matching tool_call_id's provided by the tool node."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8c6122-abf1-432b-a95b-28de500e9217",
   "metadata": {},
   "source": [
    "#### Try your own\n",
    "Take a moment and try this on your own. Run a query, check your own trace in LangSmith and see if it matches your expectation. Try expanding the calculator - maybe add a square function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146bef29-b1f2-45e1-883b-5fc51f6d54df",
   "metadata": {},
   "source": [
    "### Access and modify state within tools\n",
    "#### State\n",
    "One of the nice features of LangGraph is state. The graph has a typed data structure that is available to each node for the duration of the graph and can be persisted in long-term storage. You can use this to store information to share between nodes, to debug the graph, and to reset a long-running graph to an earlier time.\n",
    "\n",
    "When you define state for a graph, you define the data types and a 'reducer' function. The reducer describes how information is added to that element. This is especially useful when a task is mapped to multiple nodes, which are executed in parallel and update state simultaneously.\n",
    "\n",
    "In this example, the default `AgentState` was used. This is defined in [langgraph.prebuilt.chat_agent_executor](https://github.com/langchain-ai/langgraph/blob/e365b2b8bd695e03d758b19ff109152b2e342a87/libs/prebuilt/langgraph/prebuilt/chat_agent_executor.py).   \n",
    "\n",
    "```python\n",
    "    class AgentState(TypedDict):\n",
    "        \"\"\"The state of the agent.\"\"\"\n",
    "        messages: Annotated[Sequence[BaseMessage], add_messages]\n",
    "        remaining_steps: NotRequired[RemainingSteps]\n",
    "```\n",
    "        \n",
    "- `messages` are a list of `BaseMessage`, defined in [langchain_core](https://github.com/langchain-ai/langchain/blob/088095b663993b1e53cf616e1ca487d1739b0d71/libs/core/langchain_core/messages/base.py), which contains the messages to and from the LLM.\n",
    "    - typing.Annotated allows you to attach arbitrary metadata to a type hint. Syntax: Annotated[Type, metadata1, metadata2, ...] \n",
    "- The `add_messages` reducer will append new messages to the end of the message list.  \n",
    "- `remaining_steps` tracks the steps in a graph. You will see this initialized as the `recursion_limit`, but is tracked by the graph and not visibile to the user.  \n",
    "Let's take a look at this quickly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4720982e-16c2-4b90-84d6-94aba6a13e04",
   "metadata": {},
   "source": [
    "#### Custom State\n",
    "Let's extend our calculator to keep a list of all of the operations that have been performed. This will require adding a list to state, and a reducer function to add the state to the list. This will safely handle the case where the list or operation is empty."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebd4660-83b9-4a23-9108-a03cbd26877a",
   "metadata": {},
   "source": [
    "#### Accessing State \n",
    "Now, we can extend our calculator to include the update. This highlights an issue! Now state is an argument to our calculator tool. \n",
    "<img src=\"./assets/state_arg_diagram.png\" width=\"800\" style=\"display:block; margin-left:0;\">\n",
    "In the diagram, it's clear that, while the LLM is tasked with generating the tool call, it cannot form the `state` argument as it does not have that in its context!  \n",
    "The solution is to **inject the state** after the LLM.\n",
    "<img src=\"./assets/inject_state_diagram.png\" width=\"1000\" style=\"display:block; margin-left:0;\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01aea69-1704-48ff-b33d-7484e35a691b",
   "metadata": {},
   "source": [
    "<div style=\"margin:0; padding:0\">\n",
    "  <p style=\"margin:0;\">This is accomplished with the <code>InjectedState</code> annotation as shown below.</p>\n",
    "  <pre style=\"font-size:0.90em; margin:0; padding-top:0;\">\n",
    "<code class=\"language-python\">    @tool\n",
    "    def calculator_wstate(\n",
    "        operation: Literal[\"add\",\"subtract\",\"multiply\",\"divide\"],\n",
    "        a: Union[int, float],\n",
    "        b: Union[int, float],\n",
    "        <span style=\"background:#fff3a3; padding:0 2px;\">state: Annotated[CalcState, InjectedState],</span>  # ‚Üê not sent to LLM\n",
    "        <span style=\"background:#fff3a3; padding:0 2px;\">tool_call_id: Annotated[str, InjectedToolCallId],</span>  # ‚Üê not sent to LLM\n",
    "    ) -> Union[int, float]:\n",
    "</code></pre>\n",
    "<p style=\"margin:0; padding-top:4px;\">\n",
    "    This strips <code>state</code> from the description provided to the LLM, and injects it when calling the tool in <code>ToolNode</code>. the <code>tool_call_id</code> is also included. This is explained in the next section.\n",
    "  </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dcaea07-fa1b-4b1a-bd1f-c7e77a6fe451",
   "metadata": {},
   "source": [
    "#### Updating State\n",
    "You may recall that tools typically return their observations to the LLM in a `ToolMessage` that is included in `messages` field in state. To update additional members of state, we would like to extend this update.  This is done using `Command` as in the return below. \n",
    "```python\n",
    "    return Command(\n",
    "        update={\n",
    "            \"ops\": ops,\n",
    "            \"messages\": [\n",
    "                ToolMessage(f\"{result}\", tool_call_id=tool_call_id)\n",
    "            ]})\n",
    "```\n",
    "Note that to create a `ToolMessage` we needed the `tool_call_id`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578f86a4-53b4-4814-9ee5-cb8919a1c9c4",
   "metadata": {},
   "source": [
    "Let's try one more example. Notice the dual tool call in this example. The tool node will execute these in parallel."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentic-ai-tutorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
