{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e7a3a17",
   "metadata": {},
   "source": [
    "# Research Assistant\n",
    "\n",
    "## Review\n",
    "\n",
    "We've covered a few major LangGraph themes:\n",
    "\n",
    "* Memory\n",
    "* Human-in-the-loop\n",
    "* Controllability\n",
    "\n",
    "Now, we'll bring these ideas together to tackle one of AI's most popular applications: research automation. \n",
    "\n",
    "Research is often laborious work offloaded to analysts. AI has considerable potential to assist with this.\n",
    "\n",
    "However, research demands customization: raw LLM outputs are often poorly suited for real-world decision-making workflows. \n",
    "\n",
    "Customized, AI-based [research and report generation](https://jxnl.co/writing/2024/06/05/predictions-for-the-future-of-rag/#reports-over-rag) workflows are a promising way to address this.\n",
    "\n",
    "## Goal\n",
    "\n",
    "Our goal is to build a lightweight, multi-agent system around chat models that customizes the research process.\n",
    "\n",
    "`Source Selection` \n",
    "* Users can choose any set of input sources for their research.\n",
    "  \n",
    "`Planning` \n",
    "* Users provide a topic, and the system generates a team of AI analysts, each focusing on one sub-topic.\n",
    "* `Human-in-the-loop` will be used to refine these sub-topics before research begins.\n",
    "  \n",
    "`LLM Utilization`\n",
    "* Each analyst will conduct in-depth interviews with an expert AI using the selected sources.\n",
    "* The interview will be a multi-turn conversation to extract detailed insights as shown in the [STORM](https://arxiv.org/abs/2402.14207) paper.\n",
    "* These interviews will be captured in a using `sub-graphs` with their internal state. \n",
    "   \n",
    "`Research Process`\n",
    "* Experts will gather information to answer analyst questions in `parallel`.\n",
    "* And all interviews will be conducted simultaneously through `map-reduce`.\n",
    "\n",
    "`Output Format` \n",
    "* The gathered insights from each interview will be synthesized into a final report.\n",
    "* We'll use customizable prompts for the report, allowing for a flexible output format. \n",
    "\n",
    "![Screenshot 2024-08-26 at 7.26.33 PM.png](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbb164d61c93d48e604091_research-assistant1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c135f32",
   "metadata": {},
   "source": [
    "## **Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "007db312",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, operator, warnings, getpass\n",
    "from typing import List, TypedDict, Annotated\n",
    "from langgraph.graph import MessagesState\n",
    "from pydantic import BaseModel, Field\n",
    "from IPython.display import Image, display\n",
    "from langgraph.graph import START, END, StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_tavily import TavilySearch\n",
    "from langchain_community.document_loaders import WikipediaLoader\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.types import Send\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "from langchain_core.messages import get_buffer_string\n",
    "from IPython.display import Image, display, Markdown\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_groq import ChatGroq\n",
    "from prompt import *\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "923bda32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")\n",
    "_set_env(\"TAVILY_API_KEY\")\n",
    "_set_env(\"LANGSMITH_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5d03be3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello! I'm just a program, so I don't have feelings, but I'm here and ready to help you. How can I assist you today?\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "llm.invoke(\"Hello, how are you?\").content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce2815d",
   "metadata": {},
   "source": [
    "We'll use [LangSmith](https://docs.langchain.com/langsmith/home) for [tracing](https://docs.langchain.com/langsmith/observability-concepts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42104007",
   "metadata": {},
   "outputs": [],
   "source": [
    "_set_env(\"LANGSMITH_API_KEY\")\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = \"research_assistant\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6246de",
   "metadata": {},
   "source": [
    "## **Generate Analysts: Human-In-The-Loop**\n",
    "\n",
    "Create analysts and review them using human-in-the-loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d613005",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Analysts(BaseModel):\n",
    "    affiliation: str = Field(..., description=\"Primary affiliation of the analyst.\")\n",
    "    name: str = Field(..., description=\"Name of the analyst.\")\n",
    "    role: str = Field(..., description=\"Role of the analyst in the context of topic.\")\n",
    "    description: str = Field(..., description=\"Description of the analyst focus, concerns, and motives.\")\n",
    "\n",
    "    @property\n",
    "    def personality(self):\n",
    "        return f\"Name: {self.name}, \\nRole: {self.role}, \\nDescription: {self.description} \\nAffiliation: {self.affiliation}\"\n",
    "\n",
    "class Perspectives(BaseModel):\n",
    "    analyst: List[Analysts] = Field(..., description=\"comprehensive list of analysts with their roles, descriptions, and affiliations.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f549944",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenerateAnalystState(TypedDict):\n",
    "    topic: str\n",
    "    max_analysts: int\n",
    "    human_analyst_feedback: str\n",
    "    analysts: List[Analysts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8668df97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_analyst(state: GenerateAnalystState) -> dict:\n",
    "    \"\"\"Create an analyst to generate a report.\"\"\"\n",
    "    topic = state[\"topic\"]\n",
    "    max_analysts = state[\"max_analysts\"]\n",
    "    human_analyst_feedback = state.get(\"human_analyst_feedback\", \"\")\n",
    "\n",
    "    # Create a structured LLM\n",
    "    structured_llm = llm.with_structured_output(Perspectives)\n",
    "    \n",
    "    # system prompt\n",
    "    system_prompt = SystemMessage(\n",
    "        content=ANALYST_INSTRUCTIONS.format(\n",
    "            topic=topic,\n",
    "            max_analysts=max_analysts,\n",
    "            human_analyst_feedback=human_analyst_feedback,\n",
    "        ))\n",
    "    \n",
    "    # human message\n",
    "    human_message = HumanMessage(content=\"Create a set of analysts.\")\n",
    "\n",
    "    # create the analyst\n",
    "    analysts = structured_llm.invoke([system_prompt, human_message])\n",
    "\n",
    "    return {\"analysts\": analysts}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3af61462",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ANALYST_INSTRUCTIONS' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mcreate_analyst\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtopic\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mAI Agents\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_analysts\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 12\u001b[39m, in \u001b[36mcreate_analyst\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m      8\u001b[39m structured_llm = llm.with_structured_output(Perspectives)\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# system prompt\u001b[39;00m\n\u001b[32m     11\u001b[39m system_prompt = SystemMessage(\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m     content=\u001b[43mANALYST_INSTRUCTIONS\u001b[49m.format(\n\u001b[32m     13\u001b[39m         topic=topic,\n\u001b[32m     14\u001b[39m         max_analysts=max_analysts,\n\u001b[32m     15\u001b[39m         human_analyst_feedback=human_analyst_feedback,\n\u001b[32m     16\u001b[39m     ))\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# human message\u001b[39;00m\n\u001b[32m     19\u001b[39m human_message = HumanMessage(content=\u001b[33m\"\u001b[39m\u001b[33mCreate a set of analysts.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'ANALYST_INSTRUCTIONS' is not defined"
     ]
    }
   ],
   "source": [
    "create_analyst({\n",
    "    \"topic\": \"AI Agents\",\n",
    "    \"max_analysts\": 2,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e67ebee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
