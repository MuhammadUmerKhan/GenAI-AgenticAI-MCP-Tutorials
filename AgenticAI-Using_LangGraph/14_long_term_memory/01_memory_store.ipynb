{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99a72490",
   "metadata": {},
   "source": [
    "# Chatbot with Memory\n",
    "\n",
    "## Review\n",
    "\n",
    "[Memory](https://pmc.ncbi.nlm.nih.gov/articles/PMC10410470/) is a cognitive function that allows people to store, retrieve, and use information to understand their present and future. \n",
    "\n",
    "There are [various long-term memory types](https://docs.langchain.com/oss/python/concepts/memory#memory-types) that can be used in AI applications.\n",
    "\n",
    "## Goals\n",
    "\n",
    "Here, we'll introduce the [LangGraph Memory Store](https://reference.langchain.com/python/langgraph/store/?h=basestor#langgraph.store.base.BaseStore) as a way to save and retrieve long-term memories.\n",
    "\n",
    "We'll build a chatbot that uses both `short-term (within-thread)` and `long-term (across-thread)` memory.\n",
    " \n",
    "We'll focus on long-term [semantic memory](https://docs.langchain.com/oss/python/concepts/memory#semantic-memory), which will be facts about the user. \n",
    "\n",
    "These long-term memories will be used to create a personalized chatbot that can remember facts about the user.\n",
    "\n",
    "It will save memory [\"in the hot path\"](https://docs.langchain.com/oss/python/concepts/memory#writing-memories), as the user is chatting with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "61d2b116",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_groq import  ChatGroq\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "from IPython.display import Image, display\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, MessagesState, START, END\n",
    "from langgraph.store.base import BaseStore\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_core.runnables.config import RunnableConfig\n",
    "\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "from IPython.display import display, Markdown\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1690bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "store = InMemoryStore()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd243f9",
   "metadata": {},
   "source": [
    "## Introduction to the LangGraph Store\n",
    "\n",
    "The  [LangGraph Memory Store](https://reference.langchain.com/python/langgraph/store/?h=basestor#langgraph.store.base.BaseStore) provides a way to store and retrieve information *across threads* in LangGraph.\n",
    "\n",
    "This is an  [open source base class](https://blog.langchain.com/launching-long-term-memory-support-in-langgraph/) for persistent `key-value` stores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be72241",
   "metadata": {},
   "source": [
    "When storing objects (e.g., memories) in the [Store](https://reference.langchain.com/python/langgraph/store/?h=basestor#langgraph.store.base.BaseStore), we provide:\n",
    "\n",
    "- The `namespace` for the object, a tuple (similar to directories)\n",
    "- the object `key` (similar to filenames)\n",
    "- the object `value` (similar to file contents)\n",
    "\n",
    "We use the [put](https://reference.langchain.com/python/langgraph/store/?h=basestor#langgraph.store.base.BaseStore.put) method to save an object to the store by `namespace` and `key`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbc9bec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "073f5d90-88ce-420d-9d86-0e212450acea\n"
     ]
    }
   ],
   "source": [
    "# Namespace for the memory to save\n",
    "user_id = \"1\"\n",
    "namespace_for_memory = (user_id, \"memories\")\n",
    "\n",
    "# Save a memory to namespace as key and value\n",
    "key = str(uuid.uuid4())\n",
    "print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "18c191cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The value needs to be a dictionary  \n",
    "value = {\"food_preference\" : \"I like pizza\", \"name\": \"Umer\", \"age\": 20}\n",
    "\n",
    "\n",
    "store.put(namespace=namespace_for_memory, key=key, value=value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d5d3a985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1', 'memories')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store.list_namespaces()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d17c7e",
   "metadata": {},
   "source": [
    "We use [search](https://reference.langchain.com/python/langgraph/store/?h=basestor#langgraph.store.base.BaseStore.search) to retrieve objects from the store by `namespace`.\n",
    "\n",
    "This returns a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f317d69e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Search for items within a namespace prefix.\n",
    "memories = store.search(namespace_for_memory)\n",
    "type(memories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c142a63f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Item(namespace=['1', 'memories'], key='073f5d90-88ce-420d-9d86-0e212450acea', value={'food_preference': 'I like pizza', 'name': 'Umer', 'age': 20}, created_at='2026-01-05T13:28:40.971167+00:00', updated_at='2026-01-05T13:28:40.971167+00:00', score=None)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d9cc894c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'namespace': ['1', 'memories'],\n",
       " 'key': '073f5d90-88ce-420d-9d86-0e212450acea',\n",
       " 'value': {'food_preference': 'I like pizza', 'name': 'Umer', 'age': 20},\n",
       " 'created_at': '2026-01-05T13:28:40.971167+00:00',\n",
       " 'updated_at': '2026-01-05T13:28:40.971167+00:00',\n",
       " 'score': None}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memories[0].dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1c5740d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Key:** 073f5d90-88ce-420d-9d86-0e212450acea **Memory:** {'food_preference': 'I like pizza', 'name': 'Umer', 'age': 20}**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# key, value\n",
    "Markdown(f\"**Key:** {memories[0].key} **Memory:** {memories[0].value}**\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "eecaff5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'namespace': ['1', 'memories'],\n",
       " 'key': '073f5d90-88ce-420d-9d86-0e212450acea',\n",
       " 'value': {'food_preference': 'I like pizza', 'name': 'Umer', 'age': 20},\n",
       " 'created_at': '2026-01-05T13:28:40.971167+00:00',\n",
       " 'updated_at': '2026-01-05T13:28:40.971167+00:00'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the memory by namespace and key\n",
    "memory = store.get(namespace_for_memory, key)\n",
    "memory.dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "20d0cdd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'food_preference': 'I like pizza', 'name': 'Umer', 'age': 20}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef466c0c",
   "metadata": {},
   "source": [
    "We can also use [get](https://reference.langchain.com/python/langgraph/store/?h=basestor#langgraph.store.base.BaseStore.get) to retrieve an object by `namespace` and `key`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94539cb0",
   "metadata": {},
   "source": [
    "## Chatbot with long-term memory\n",
    "\n",
    "We want a chatbot that [has two types of memory](https://docs.google.com/presentation/d/181mvjlgsnxudQI6S3ritg9sooNyu4AcLLFH1UK0kIuk/edit#slide=id.g30eb3c8cf10_0_156):\n",
    "\n",
    "1. `Short-term (within-thread) memory`: Chatbot can persist conversational history and / or allow interruptions in a chat session.\n",
    "2. `Long-term (cross-thread) memory`: Chatbot can remember information about a specific user *across all chat sessions*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abcaa44",
   "metadata": {},
   "source": [
    "For `short-term memory`, we'll use a [checkpointer](https://docs.langchain.com/oss/python/langgraph/persistence#checkpointer-libraries). \n",
    "\n",
    "See Module 2 and our [conceptual docs](https://docs.langchain.com/oss/python/langgraph/persistence) for more on checkpointers, but in summary:\n",
    "\n",
    "* They write the graph state at each step to a thread.\n",
    "* They persist the chat history in the thread.\n",
    "* They allow the graph to be interrupted and / or resumed from any step in the thread.\n",
    " \n",
    "And, for `long-term memory`, we'll use the [LangGraph Store](https://reference.langchain.com/python/langgraph/store/?h=basestor#langgraph.store.base.BaseStore) as introduced above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2d691c85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! How can I assist you today?'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ChatOpenAI(model=\"gpt-4.1-nano\", temperature=0)\n",
    "model.invoke(\"hello\").content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0847a382",
   "metadata": {},
   "source": [
    "The chat history will be saved to short-term memory using the checkpointer.\n",
    "\n",
    "The chatbot will reflect on the chat history. \n",
    "\n",
    "It will then create and save a memory to the [LangGraph Store](https://reference.langchain.com/python/langgraph/store/?h=basestor#langgraph.store.base.BaseStore).\n",
    "\n",
    "This memory is accessible in future chat sessions to personalize the chatbot's responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1e0826b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chatbot instruction\n",
    "MODEL_SYSTEM_MESSAGE = \"\"\"\n",
    "    You are a helpful assistant with memory that provides information about the user. \n",
    "    If you have memory for this user, use it to personalize your responses.\n",
    "    Here is the memory (it may be empty): {memory}\n",
    "\"\"\"\n",
    "\n",
    "# Create new memory from the chat history and any existing memory\n",
    "CREATE_MEMORY_INSTRUCTION = \"\"\"\"\n",
    "    You are collecting information about the user to personalize your responses.\n",
    "\n",
    "    CURRENT USER INFORMATION: {memory}\n",
    "\n",
    "    INSTRUCTIONS:\n",
    "        1. Review the chat history below carefully\n",
    "        2. Identify new information about the user, such as:\n",
    "            - Personal details (name, location)\n",
    "            - Preferences (likes, dislikes)\n",
    "            - Interests and hobbies\n",
    "            - Past experiences\n",
    "            - Goals or future plans\n",
    "        3. Merge any new information with existing memory\n",
    "        4. Format the memory as a clear, bulleted list\n",
    "        5. If new information conflicts with existing memory, keep the most recent version\n",
    "\n",
    "    Remember: Only include factual information directly stated by the user. Do not make assumptions or inferences.\n",
    "\n",
    "    Based on the chat history below, please update the user information:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f8895f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatModel(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
    "    \"\"\"Load memory from the store and use it to personalize the chatbot's response.\"\"\"\n",
    "\n",
    "    # get the user ID from the store\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "\n",
    "    # retreive memory from the store\n",
    "    namespace = (\"memory\", user_id)\n",
    "    key = \"user_memory\"\n",
    "    existing_memory = store.get(namespace, key)\n",
    "\n",
    "    # extract the memory\n",
    "    if existing_memory:\n",
    "        # value is a dictionary with a memory key\n",
    "        existing_memory_content = existing_memory.value.get(\"memory\")\n",
    "    else:\n",
    "        existing_memory_content = \"No existing memory found.\"\n",
    "\n",
    "    # format the memory in the system prompt\n",
    "    system_msg = SystemMessage(content=MODEL_SYSTEM_MESSAGE.format(memory=existing_memory_content))\n",
    "\n",
    "    # respond using memory as well as the chat history\n",
    "    response = model.invoke([system_msg] + state[\"messages\"])\n",
    "\n",
    "    return {\"messages\": response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3014a3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_memory(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
    "    \"\"\"Create new memory from the chat history and any existing memory, then save it to the store.\"\"\"\n",
    "\n",
    "    # get the user ID from the store\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "\n",
    "    # retreive memory from the store\n",
    "    namespace = (\"memory\", user_id)\n",
    "    key = \"user_memory\"\n",
    "    existing_memory = store.get(namespace, key)\n",
    "\n",
    "    # Extract the actual memory content if it exists\n",
    "    if existing_memory:\n",
    "        # Value is a dictionary with a memory key\n",
    "        existing_memory_content = existing_memory.value.get(\"memory\")\n",
    "    else:\n",
    "        existing_memory_content = \"No existing memory found.\"\n",
    "\n",
    "    # Format the memory in the system prompt\n",
    "    system_msg = SystemMessage(content=CREATE_MEMORY_INSTRUCTION.format(memory=existing_memory_content))\n",
    "    new_memory = model.invoke([system_msg] + state[\"messages\"])\n",
    "\n",
    "    # Overwrite the existing memory in the store\n",
    "    key = \"user_memory\"\n",
    "    store.put(namespace, key, {\"memory\": new_memory.content})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "165be432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the graph\n",
    "graph_builder = StateGraph(MessagesState)\n",
    "\n",
    "# Add graph nodes\n",
    "graph_builder.add_node(\"chatModel\", chatModel)\n",
    "graph_builder.add_node(\"write_memory\", write_memory)\n",
    "\n",
    "# Define the graph edges\n",
    "graph_builder.add_edge(START, \"chatModel\")\n",
    "graph_builder.add_edge(\"chatModel\", \"write_memory\")\n",
    "graph_builder.add_edge(\"write_memory\", END)\n",
    "\n",
    "# Store for long-term (across-thread) memory\n",
    "across_thread_memory = InMemoryStore()\n",
    "\n",
    "# Checkpointer for short-term (within-thread) memory\n",
    "within_thread_memory = MemorySaver()\n",
    "\n",
    "# Build the graph\n",
    "graph = graph_builder.compile(checkpointer=within_thread_memory, store=across_thread_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9933aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e985469",
   "metadata": {},
   "source": [
    "When we interact with the chatbot, we supply two things:\n",
    "\n",
    "1. `Short-term (within-thread) memory`: A `thread ID` for persisting the chat history.\n",
    "2. `Long-term (cross-thread) memory`: A `user ID` to namespace long-term memories to the user.\n",
    "\n",
    "Let's see how these work together in practice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "68019246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hi, I'm Umer. I love hiking and wandering.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hi Umer! It's great to meet someone who loves hiking and wandering. Do you have any favorite trails or places you'd like to explore next?\n"
     ]
    }
   ],
   "source": [
    "# We supply a thread ID for short-term (within-thread) memory\n",
    "# We supply a user ID for long-term (across-thread) memory \n",
    "config = { \"configurable\": { \"thread_id\" : \"1\", \"user_id\" : \"1\" } }\n",
    "\n",
    "# user input\n",
    "input_messages = [HumanMessage(content=\"Hi, I'm Umer. I love hiking and wandering.\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "318fa538",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'namespace': ['memory', '1'],\n",
       " 'key': 'user_memory',\n",
       " 'value': {'memory': '- Name: Umer\\n- Interests and hobbies: Hiking and wandering'},\n",
       " 'created_at': '2026-01-05T14:18:39.015620+00:00',\n",
       " 'updated_at': '2026-01-05T14:18:39.015620+00:00'}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Namespace for the memory to save\n",
    "user_id = \"1\"\n",
    "namespace = (\"memory\", user_id)\n",
    "existing_memory = across_thread_memory.get(namespace, \"user_memory\")\n",
    "\n",
    "existing_memory.dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a38a7fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hi! Where would you recommend that I go biking?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hi Umer! Since you enjoy hiking and wandering, you might also enjoy exploring scenic biking trails. Depending on your location, I can recommend some great spots. If you're looking for general ideas, national parks, mountain trails, or coastal paths often offer fantastic biking experiences. Let me know where you're located or if you have a specific type of scenery you prefer, and I can give you more tailored suggestions!\n"
     ]
    }
   ],
   "source": [
    "# We supply a user ID for across-thread memory as well as a new thread ID\n",
    "config = {\"configurable\": {\"thread_id\": \"2\", \"user_id\": \"1\"}}\n",
    "\n",
    "# User input \n",
    "input_messages = [HumanMessage(content=\"Hi! Where would you recommend that I go biking?\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b3afb4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentic-ai-tutorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
