{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d561a42",
   "metadata": {},
   "source": [
    "# **LangChain**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8260d41f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e2b2a6",
   "metadata": {},
   "source": [
    "## **Summarize messages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "290dfac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langchain.agents.middleware import SummarizationMiddleware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "caedc00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_agent(\n",
    "    model=\"gpt-5-nano\",\n",
    "    checkpointer=InMemorySaver(),\n",
    "\n",
    "    middleware=[\n",
    "        SummarizationMiddleware(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            trigger=(\"tokens\", 100),\n",
    "            keep=(\"messages\", 1)\n",
    "        )\n",
    "    ]\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7db22c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.messages import HumanMessage, AIMessage\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9024acd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='Here is a summary of the conversation to date:\\n\\nThe capital of the moon is Lunapolis. The weather in Lunapolis features clear skies, with a high of 120C and a low of -100C. There are 100,000 cheese miners living in Lunapolis, and they may strike due to dissatisfaction with the new president.', additional_kwargs={}, response_metadata={}, id='d7bb2083-66cc-483b-afc5-dff96599b89b'),\n",
      "              HumanMessage(content=\"If you were Lunapolis' new president how would you respond to the cheese miners' union?\", additional_kwargs={}, response_metadata={}, id='18430be5-3a4a-4aa4-b949-36019dc5e064'),\n",
      "              AIMessage(content='If I were Lunapolis’ new president, I’d treat the Cheese Miners’ Union as a respected partner and aim for a swift, fair, and sustainable resolution. Here’s a practical plan I would follow.\\n\\nKey principles\\n- Safety first: ensure every worker goes home safe. Any concessions must not compromise safety.\\n- Respect and transparency: open dialogue, no surprises, clear data on costs, benefits, and constraints.\\n- Shared prosperity: fair compensation, benefits, and working conditions linked to productivity and risk.\\n- Predictability and accountability: establish concrete timelines, measurable goals, and a clear dispute-resolution process.\\n- Preserve essential services: keep cheese production steady while negotiations continue.\\n\\nImmediate actions (first 2–3 weeks)\\n- Create a joint Cheese Miners Negotiation Council with union reps, management, and a neutral mediator (if requested).\\n- Publicly acknowledge the miners’ concerns and commit to a good-faith negotiating process.\\n- Freeze or limit disciplinary actions related to union activity; guarantee the right to organize and bargain.\\n- Conduct a comprehensive needs assessment quickly: wages, benefits, overtime, shift schedules, safety conditions, PPE, housing/commuting, health care, and training.\\n- Review the budget with a focus on safety and reliability: identify non‑essential costs that can be redirected toward worker-facing improvements.\\n\\nShort-term measures (2–6 weeks)\\n- Safety improvements: audit and upgrade PPE, expand safety training, implement more frequent breaks, cap extreme-shift exposure where feasible, and ensure reliable climate control in work areas.\\n- Temporary enhancements: consider a temporary wage or hazard-pay increase if financially feasible, plus overtime protections and meal/transport allowances for high-risk shifts.\\n- Communication cadence: weekly update meetings with union leadership; publish a public progress dashboard on safety, wage, and benefit changes.\\n- Grievance mechanism: establish a fast-track process for addressing specific complaints, with clear timelines for responses.\\n\\nMedium-term measures (2–6 months)\\n- Wages and benefits framework: agree on a structured wage scale with annual cost-of-living adjustments, a fair overtime policy, and a benefits package (healthcare, pension/retirement, education subsidies).\\n- Training and career ladders: formalized programs to retrain workers for higher-skilled tasks or safer, lower-risk roles; tie progression to clear competency milestones.\\n- Health and safety investments: capital plan for ongoing safety improvements, climate-control upgrades, and better housing/commuting options if applicable.\\n- Profit/production linkage (optional): consider a modest profit-sharing or bonus plan tied to safety records, uptime, and quality metrics to align incentives.\\n\\nLong-term structural outcomes (6–12+ months)\\n- Workforce resilience: expand automation thoughtfully to reduce hazardous exposure while preserving jobs; implement retraining pipelines so workers can move to safer or higher-skill roles.\\n- Governance: formalize a long-term labor relations framework with periodic wage/benefit reviews, joint safety committees, and annual strategy sessions.\\n- Community and morale: establish ongoing worker welfare programs (e.g., family support, health programs, education grants) to sustain high morale and retention.\\n\\nNegotiation framework and example offers\\n- Start with data-driven proposals: present current costs, projected productivity, and the minimum viable package that ensures safety and stability.\\n- Offer package (example structure, numbers can be adjusted to the colony’s finances):\\n  - Immediate hazard-pay increase for extreme-temperature work and high-risk tasks (tiered by exposure level).\\n  - Overtime premium standardization (e.g., time-and-a-half or higher for mandatory overtime with caps on consecutive days).\\n  - Annual wage scale with fixed cost-of-living adjustments.\\n  - Enhanced health care and retirement benefits, plus travel/housing allowances if applicable.\\n  - Formal safety improvements funded through a dedicated budget line.\\n  - Jointly administered training and career ladder program.\\n- Ask for in exchange:\\n  - A defined pause on strikes for a 60–90 day ramp-up period while negotiations proceed.\\n  - Agreement to a structured review timetable (every 3-6 months) with independent auditing on safety and compliance.\\n  - Agreement to avoid work stoppages during critical production periods, with exceptions handled through the negotiation process.\\n\\nPublic messaging to the union and the public\\n- Opening statement to miners: “I hear you. Your safety, your wages, and your future on Lunapolis matter to me. We will negotiate in good faith, grounded in data, with the aim of reaching a fair agreement that protects you, your families, and our colony’s long-term vitality.”\\n- Public note: emphasize safety, fairness, and collaboration. Reassure the broader community that negotiations will not threaten food supply or essential services.\\n\\nSample communications\\n- Opening to Cheese Miners’ Union: “We value your work and the essential role you play in Lunapolis. Today I commit to an open, data-driven negotiation focused on safety, fair pay, reasonable benefits, and a plan for the future. We will bring in a neutral mediator if you request one, and I pledge transparent updates at every milestone.”\\n- Public update (after key milestones): “We have made progress on safety enhancements, reviewed our compensation framework, and established a joint council to oversee implementation. Our priority remains the health and well-being of our miners and the reliability of Lunapolis’ operations.”\\n\\nRisk considerations\\n- Financial constraints: be prepared to reallocate budgets and implement phased improvements. If finances are tight, prioritize safety and liveability first, with phased wage actions contingent on revenue.\\n- Strike risk: aim to reduce the probability by rapid wins on safety and scheduling, plus a credible, time-bound plan for ongoing negotiation.\\n- External factors: weather extremes, supply chain obligations, and mission-critical production windows should be protected through contingency planning.\\n\\nIf you want, I can tailor this to specific numbers you imagine for Lunapolis’ budget, tax/tariff structure, or the miners’ current wage and benefit baseline. I can also draft a more detailed 30-, 60-, and 90-day action calendar with concrete milestones.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 2700, 'prompt_tokens': 97, 'total_tokens': 2797, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 1472, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-Cpb2Ey9XBh2NL8qcsfsLiZvcFtpkt', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b466d-4aaf-7a80-aa43-be8988377d70-0', usage_metadata={'input_tokens': 97, 'output_tokens': 2700, 'total_tokens': 2797, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 1472}})]}\n"
     ]
    }
   ],
   "source": [
    "response = agent.invoke(\n",
    "    {\"messages\": [\n",
    "        HumanMessage(content=\"What is the capital of the moon?\"),\n",
    "        AIMessage(content=\"The capital of the moon is Lunapolis.\"),\n",
    "        HumanMessage(content=\"What is the weather in Lunapolis?\"),\n",
    "        AIMessage(content=\"Skies are clear, with a high of 120C and a low of -100C.\"),\n",
    "        HumanMessage(content=\"How many cheese miners live in Lunapolis?\"),\n",
    "        AIMessage(content=\"There are 100,000 cheese miners living in Lunapolis.\"),\n",
    "        HumanMessage(content=\"Do you think the cheese miners' union will strike?\"),\n",
    "        AIMessage(content=\"Yes, because they are unhappy with the new president.\"),\n",
    "        HumanMessage(content=\"If you were Lunapolis' new president how would you respond to the cheese miners' union?\"),\n",
    "        ]},\n",
    "    {\"configurable\": {\"thread_id\": \"1\"}}\n",
    ")\n",
    "\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ebb3a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If I were Lunapolis’ new president, I’d treat the Cheese Miners’ Union as a respected partner and aim for a swift, fair, and sustainable resolution. Here’s a practical plan I would follow.\n",
      "\n",
      "Key principles\n",
      "- Safety first: ensure every worker goes home safe. Any concessions must not compromise safety.\n",
      "- Respect and transparency: open dialogue, no surprises, clear data on costs, benefits, and constraints.\n",
      "- Shared prosperity: fair compensation, benefits, and working conditions linked to productivity and risk.\n",
      "- Predictability and accountability: establish concrete timelines, measurable goals, and a clear dispute-resolution process.\n",
      "- Preserve essential services: keep cheese production steady while negotiations continue.\n",
      "\n",
      "Immediate actions (first 2–3 weeks)\n",
      "- Create a joint Cheese Miners Negotiation Council with union reps, management, and a neutral mediator (if requested).\n",
      "- Publicly acknowledge the miners’ concerns and commit to a good-faith negotiating process.\n",
      "- Freeze or limit disciplinary actions related to union activity; guarantee the right to organize and bargain.\n",
      "- Conduct a comprehensive needs assessment quickly: wages, benefits, overtime, shift schedules, safety conditions, PPE, housing/commuting, health care, and training.\n",
      "- Review the budget with a focus on safety and reliability: identify non‑essential costs that can be redirected toward worker-facing improvements.\n",
      "\n",
      "Short-term measures (2–6 weeks)\n",
      "- Safety improvements: audit and upgrade PPE, expand safety training, implement more frequent breaks, cap extreme-shift exposure where feasible, and ensure reliable climate control in work areas.\n",
      "- Temporary enhancements: consider a temporary wage or hazard-pay increase if financially feasible, plus overtime protections and meal/transport allowances for high-risk shifts.\n",
      "- Communication cadence: weekly update meetings with union leadership; publish a public progress dashboard on safety, wage, and benefit changes.\n",
      "- Grievance mechanism: establish a fast-track process for addressing specific complaints, with clear timelines for responses.\n",
      "\n",
      "Medium-term measures (2–6 months)\n",
      "- Wages and benefits framework: agree on a structured wage scale with annual cost-of-living adjustments, a fair overtime policy, and a benefits package (healthcare, pension/retirement, education subsidies).\n",
      "- Training and career ladders: formalized programs to retrain workers for higher-skilled tasks or safer, lower-risk roles; tie progression to clear competency milestones.\n",
      "- Health and safety investments: capital plan for ongoing safety improvements, climate-control upgrades, and better housing/commuting options if applicable.\n",
      "- Profit/production linkage (optional): consider a modest profit-sharing or bonus plan tied to safety records, uptime, and quality metrics to align incentives.\n",
      "\n",
      "Long-term structural outcomes (6–12+ months)\n",
      "- Workforce resilience: expand automation thoughtfully to reduce hazardous exposure while preserving jobs; implement retraining pipelines so workers can move to safer or higher-skill roles.\n",
      "- Governance: formalize a long-term labor relations framework with periodic wage/benefit reviews, joint safety committees, and annual strategy sessions.\n",
      "- Community and morale: establish ongoing worker welfare programs (e.g., family support, health programs, education grants) to sustain high morale and retention.\n",
      "\n",
      "Negotiation framework and example offers\n",
      "- Start with data-driven proposals: present current costs, projected productivity, and the minimum viable package that ensures safety and stability.\n",
      "- Offer package (example structure, numbers can be adjusted to the colony’s finances):\n",
      "  - Immediate hazard-pay increase for extreme-temperature work and high-risk tasks (tiered by exposure level).\n",
      "  - Overtime premium standardization (e.g., time-and-a-half or higher for mandatory overtime with caps on consecutive days).\n",
      "  - Annual wage scale with fixed cost-of-living adjustments.\n",
      "  - Enhanced health care and retirement benefits, plus travel/housing allowances if applicable.\n",
      "  - Formal safety improvements funded through a dedicated budget line.\n",
      "  - Jointly administered training and career ladder program.\n",
      "- Ask for in exchange:\n",
      "  - A defined pause on strikes for a 60–90 day ramp-up period while negotiations proceed.\n",
      "  - Agreement to a structured review timetable (every 3-6 months) with independent auditing on safety and compliance.\n",
      "  - Agreement to avoid work stoppages during critical production periods, with exceptions handled through the negotiation process.\n",
      "\n",
      "Public messaging to the union and the public\n",
      "- Opening statement to miners: “I hear you. Your safety, your wages, and your future on Lunapolis matter to me. We will negotiate in good faith, grounded in data, with the aim of reaching a fair agreement that protects you, your families, and our colony’s long-term vitality.”\n",
      "- Public note: emphasize safety, fairness, and collaboration. Reassure the broader community that negotiations will not threaten food supply or essential services.\n",
      "\n",
      "Sample communications\n",
      "- Opening to Cheese Miners’ Union: “We value your work and the essential role you play in Lunapolis. Today I commit to an open, data-driven negotiation focused on safety, fair pay, reasonable benefits, and a plan for the future. We will bring in a neutral mediator if you request one, and I pledge transparent updates at every milestone.”\n",
      "- Public update (after key milestones): “We have made progress on safety enhancements, reviewed our compensation framework, and established a joint council to oversee implementation. Our priority remains the health and well-being of our miners and the reliability of Lunapolis’ operations.”\n",
      "\n",
      "Risk considerations\n",
      "- Financial constraints: be prepared to reallocate budgets and implement phased improvements. If finances are tight, prioritize safety and liveability first, with phased wage actions contingent on revenue.\n",
      "- Strike risk: aim to reduce the probability by rapid wins on safety and scheduling, plus a credible, time-bound plan for ongoing negotiation.\n",
      "- External factors: weather extremes, supply chain obligations, and mission-critical production windows should be protected through contingency planning.\n",
      "\n",
      "If you want, I can tailor this to specific numbers you imagine for Lunapolis’ budget, tax/tariff structure, or the miners’ current wage and benefit baseline. I can also draft a more detailed 30-, 60-, and 90-day action calendar with concrete milestones.\n"
     ]
    }
   ],
   "source": [
    "print(response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59ae4bd",
   "metadata": {},
   "source": [
    "## **Trim/delete messages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a20e78ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "from langchain.agents import AgentState\n",
    "from langchain.messages import RemoveMessage\n",
    "from langgraph.runtime import Runtime\n",
    "from langchain.agents.middleware import before_agent\n",
    "from langchain.messages import ToolMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "857a29a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@before_agent\n",
    "def trim_message(state: AgentState, runtime: Runtime) -> dict[str, Any]:\n",
    "    \"\"\"Remove all the tool message from the state\"\"\"\n",
    "\n",
    "    messages = state[\"messages\"]\n",
    "\n",
    "    tool_messages = [m for m in messages if isinstance(m, ToolMessage)]\n",
    "    return { \"messages\": [RemoveMessage(id=m.id) for m in tool_messages] }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29f321ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_agent(\n",
    "    model=\"gpt-5-nano\",\n",
    "    checkpointer=InMemorySaver(),\n",
    "    middleware=[trim_message],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "710a36a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content=\"My device won't turn on. What should I do?\", additional_kwargs={}, response_metadata={}, id='96fbe144-2153-4eb2-9790-65f45f390920'),\n",
      "              AIMessage(content='Is the device plugged in and turned on?', additional_kwargs={}, response_metadata={}, id='ca3bbc25-4640-44d9-80ff-56ee331a002c'),\n",
      "              HumanMessage(content=\"Yes, it's plugged in and turned on.\", additional_kwargs={}, response_metadata={}, id='9d7e25f7-29c1-43bb-acca-5216d13533ce'),\n",
      "              AIMessage(content='Is the device showing any lights or indicators?', additional_kwargs={}, response_metadata={}, id='bdfb4b3e-e6f5-444a-a763-f5d65515eda0'),\n",
      "              HumanMessage(content=\"What's the temperature of the device?\", additional_kwargs={}, response_metadata={}, id='8d44c5e9-fd42-4730-ad7a-a2151c2d5a5a'),\n",
      "              AIMessage(content='I can’t read the device’s internal temperature from here. If it can’t power on, you won’t be able to read its temperature anyway. You can, however, take these steps to troubleshoot and reduce overheating risk:\\n\\n- If it feels hot, power it off and unplug it. Let it cool for 15–30 minutes before trying again.\\n- Try a different power adapter and/or outlet to rule out a faulty charger or outlet.\\n- Disconnect all peripherals (USB devices, HDMI, etc.). Do a hard reset: press and hold the power button for 15–20 seconds, then try turning it on again.\\n- If it’s a laptop with a removable battery, remove the battery, plug in the charger, and try to power on with only the charger connected.\\n- Check for any indicator lights or beeps when you attempt to power it on and note the pattern. Refer to your device manual for what the codes mean.\\n- Look for obvious signs of damage, burning smell, or liquid exposure. If you see any, stop and seek service.\\n\\nIf you can share more details (device type, model, any lights/beeps, steps you’ve already tried), I can tailor the troubleshooting steps for you.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 1727, 'prompt_tokens': 71, 'total_tokens': 1798, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 1472, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-Cpb8cp7e30rdkFQqIw23f7idJMED7', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b4673-5593-7d43-86a8-624baad5ff1a-0', usage_metadata={'input_tokens': 71, 'output_tokens': 1727, 'total_tokens': 1798, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 1472}})]}\n"
     ]
    }
   ],
   "source": [
    "response = agent.invoke(\n",
    "    {\"messages\": [\n",
    "        HumanMessage(content=\"My device won't turn on. What should I do?\"),\n",
    "        ToolMessage(content=\"blorp-x7 initiating diagnostic ping…\", tool_call_id=\"1\"),\n",
    "        AIMessage(content=\"Is the device plugged in and turned on?\"),\n",
    "        HumanMessage(content=\"Yes, it's plugged in and turned on.\"),\n",
    "        ToolMessage(content=\"temp=42C voltage=2.9v … greeble complete.\", tool_call_id=\"2\"),\n",
    "        AIMessage(content=\"Is the device showing any lights or indicators?\"),\n",
    "        HumanMessage(content=\"What's the temperature of the device?\")\n",
    "        ]},\n",
    "    {\"configurable\": {\"thread_id\": \"2\"}}\n",
    ")\n",
    "\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06b42539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I can’t read the device’s internal temperature from here. If it can’t power on, you won’t be able to read its temperature anyway. You can, however, take these steps to troubleshoot and reduce overheating risk:\n",
      "\n",
      "- If it feels hot, power it off and unplug it. Let it cool for 15–30 minutes before trying again.\n",
      "- Try a different power adapter and/or outlet to rule out a faulty charger or outlet.\n",
      "- Disconnect all peripherals (USB devices, HDMI, etc.). Do a hard reset: press and hold the power button for 15–20 seconds, then try turning it on again.\n",
      "- If it’s a laptop with a removable battery, remove the battery, plug in the charger, and try to power on with only the charger connected.\n",
      "- Check for any indicator lights or beeps when you attempt to power it on and note the pattern. Refer to your device manual for what the codes mean.\n",
      "- Look for obvious signs of damage, burning smell, or liquid exposure. If you see any, stop and seek service.\n",
      "\n",
      "If you can share more details (device type, model, any lights/beeps, steps you’ve already tried), I can tailor the troubleshooting steps for you.\n"
     ]
    }
   ],
   "source": [
    "print(response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68147f2e",
   "metadata": {},
   "source": [
    "# **LangGraph**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d1806890",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, StateGraph, END\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langchain.agents.middleware import SummarizationMiddleware\n",
    "from langchain_classic.prompts import ChatPromptTemplate\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import BaseMessage, SystemMessage, ToolMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from typing_extensions import TypedDict\n",
    "from typing import Annotated, List\n",
    "from IPython.display import Markdown\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1dbd40f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-5-nano\", max_completion_tokens=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0fba9e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[List[BaseMessage], add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "85f551ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_tokens(messages: List[BaseMessage]) -> int:\n",
    "    \"\"\"Approximate token counter.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    return sum(len(encoding.encode(str(m))) for m in messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "8d72de7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarization_middleware_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    Custom middleware node: Summarizes if >100 tokens, keeps 1 recent msg + summary.\n",
    "    \"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    if count_tokens(messages) <= 100 or len(messages) <= 2:\n",
    "        return state  # No change\n",
    "\n",
    "    # Prompt for summary\n",
    "    summary_prompt = ChatPromptTemplate.from_template(\n",
    "        \"Summarize this conversation history in 1-2 sentences, preserving key facts:\\n\\n{history}\"\n",
    "    )\n",
    "\n",
    "    summary_llm = ChatOpenAI(model=\"gpt-4o-mini\", max_completion_tokens=512)\n",
    "\n",
    "    chain = summary_prompt | summary_llm\n",
    "\n",
    "    history_str = \"\\n\".join([f\"{m.type}: {m.content}\" for m in messages[:-1]])  # Exclude last\n",
    "    summary = chain.invoke({\"history\": history_str})\n",
    "\n",
    "    # New state: Summary (as SystemMessage) + last msg\n",
    "    new_messages = [\n",
    "        SystemMessage(content=f\"Conversation summary: {summary.content}\"),\n",
    "        messages[-1]  # Keep latest\n",
    "    ]\n",
    "    return {\"messages\": new_messages}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "6b0cbcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatNode(state: AgentState) -> AgentState:\n",
    "    response = llm.invoke(state[\"messages\"])\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "tools = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e6fd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(AgentState)\n",
    "\n",
    "graph.add_node(\"llm\", chatNode)\n",
    "graph.add_node(\"SummarizationMiddleware\", summarization_middleware_node)\n",
    "graph.add_node(\"tools\", ToolNode(tools))\n",
    "\n",
    "graph.add_edge(START, \"SummarizationMiddleware\")\n",
    "graph.add_edge(\"SummarizationMiddleware\", \"llm\")\n",
    "graph.add_conditional_edges(\"llm\", tools_condition)\n",
    "graph.add_edge(\"llm\", END)\n",
    "\n",
    "workflow = graph.compile(checkpointer=InMemorySaver())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "02f72dfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x0000015B572A44D0>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "2c22a355",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "19 validation errors for HumanMessage\ncontent.str\n  Input should be a valid string [type=string_type, input_value=AIMessage(content='', add...: 0, 'reasoning': 512}}), input_type=AIMessage]\n    For further information visit https://errors.pydantic.dev/2.12/v/string_type\ncontent.list[union[str,dict[any,any]]].0.str\n  Input should be a valid string [type=string_type, input_value=('content', ''), input_type=tuple]\n    For further information visit https://errors.pydantic.dev/2.12/v/string_type\ncontent.list[union[str,dict[any,any]]].0.dict[any,any]\n  Input should be a valid dictionary [type=dict_type, input_value=('content', ''), input_type=tuple]\n    For further information visit https://errors.pydantic.dev/2.12/v/dict_type\ncontent.list[union[str,dict[any,any]]].1.str\n  Input should be a valid string [type=string_type, input_value=('additional_kwargs', {'refusal': None}), input_type=tuple]\n    For further information visit https://errors.pydantic.dev/2.12/v/string_type\ncontent.list[union[str,dict[any,any]]].1.dict[any,any]\n  Input should be a valid dictionary [type=dict_type, input_value=('additional_kwargs', {'refusal': None}), input_type=tuple]\n    For further information visit https://errors.pydantic.dev/2.12/v/dict_type\ncontent.list[union[str,dict[any,any]]].2.str\n  Input should be a valid string [type=string_type, input_value=('response_metadata', {'t...gth', 'logprobs': None}), input_type=tuple]\n    For further information visit https://errors.pydantic.dev/2.12/v/string_type\ncontent.list[union[str,dict[any,any]]].2.dict[any,any]\n  Input should be a valid dictionary [type=dict_type, input_value=('response_metadata', {'t...gth', 'logprobs': None}), input_type=tuple]\n    For further information visit https://errors.pydantic.dev/2.12/v/dict_type\ncontent.list[union[str,dict[any,any]]].3.str\n  Input should be a valid string [type=string_type, input_value=('type', 'ai'), input_type=tuple]\n    For further information visit https://errors.pydantic.dev/2.12/v/string_type\ncontent.list[union[str,dict[any,any]]].3.dict[any,any]\n  Input should be a valid dictionary [type=dict_type, input_value=('type', 'ai'), input_type=tuple]\n    For further information visit https://errors.pydantic.dev/2.12/v/dict_type\ncontent.list[union[str,dict[any,any]]].4.str\n  Input should be a valid string [type=string_type, input_value=('name', None), input_type=tuple]\n    For further information visit https://errors.pydantic.dev/2.12/v/string_type\ncontent.list[union[str,dict[any,any]]].4.dict[any,any]\n  Input should be a valid dictionary [type=dict_type, input_value=('name', None), input_type=tuple]\n    For further information visit https://errors.pydantic.dev/2.12/v/dict_type\ncontent.list[union[str,dict[any,any]]].5.str\n  Input should be a valid string [type=string_type, input_value=('id', 'lc_run--019b46b1-...61-89a9-f1f0a69e4038-0'), input_type=tuple]\n    For further information visit https://errors.pydantic.dev/2.12/v/string_type\ncontent.list[union[str,dict[any,any]]].5.dict[any,any]\n  Input should be a valid dictionary [type=dict_type, input_value=('id', 'lc_run--019b46b1-...61-89a9-f1f0a69e4038-0'), input_type=tuple]\n    For further information visit https://errors.pydantic.dev/2.12/v/dict_type\ncontent.list[union[str,dict[any,any]]].6.str\n  Input should be a valid string [type=string_type, input_value=('tool_calls', []), input_type=tuple]\n    For further information visit https://errors.pydantic.dev/2.12/v/string_type\ncontent.list[union[str,dict[any,any]]].6.dict[any,any]\n  Input should be a valid dictionary [type=dict_type, input_value=('tool_calls', []), input_type=tuple]\n    For further information visit https://errors.pydantic.dev/2.12/v/dict_type\ncontent.list[union[str,dict[any,any]]].7.str\n  Input should be a valid string [type=string_type, input_value=('invalid_tool_calls', []), input_type=tuple]\n    For further information visit https://errors.pydantic.dev/2.12/v/string_type\ncontent.list[union[str,dict[any,any]]].7.dict[any,any]\n  Input should be a valid dictionary [type=dict_type, input_value=('invalid_tool_calls', []), input_type=tuple]\n    For further information visit https://errors.pydantic.dev/2.12/v/dict_type\ncontent.list[union[str,dict[any,any]]].8.str\n  Input should be a valid string [type=string_type, input_value=('usage_metadata', {'inpu...: 0, 'reasoning': 512}}), input_type=tuple]\n    For further information visit https://errors.pydantic.dev/2.12/v/string_type\ncontent.list[union[str,dict[any,any]]].8.dict[any,any]\n  Input should be a valid dictionary [type=dict_type, input_value=('usage_metadata', {'inpu...: 0, 'reasoning': 512}}), input_type=tuple]\n    For further information visit https://errors.pydantic.dev/2.12/v/dict_type",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValidationError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[113]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m      1\u001b[39m test_messages = [\n\u001b[32m      2\u001b[39m     HumanMessage(content=\u001b[33m\"\u001b[39m\u001b[33mCheck my device status\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m      3\u001b[39m     AIMessage(\n\u001b[32m   (...)\u001b[39m\u001b[32m     19\u001b[39m     HumanMessage(content=\u001b[33m\"\u001b[39m\u001b[33mAlso check battery level\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     20\u001b[39m ]\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# Now invoke — should work!\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m response = \u001b[43mworkflow\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_messages\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mconfigurable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mthread_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtest1\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[38;5;28mprint\u001b[39m(response[\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m][-\u001b[32m1\u001b[39m].content)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Gen-Agentic-AI-Tutorials\\.venv\\Lib\\site-packages\\langgraph\\pregel\\main.py:3068\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[39m\n\u001b[32m   3065\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | Any] = []\n\u001b[32m   3066\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m3068\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3069\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3070\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3071\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3072\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdates\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   3073\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m   3074\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3075\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3076\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3077\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3078\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3079\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3080\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3081\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3082\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   3083\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Gen-Agentic-AI-Tutorials\\.venv\\Lib\\site-packages\\langgraph\\pregel\\main.py:2643\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2641\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2642\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2643\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2644\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2645\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2646\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2647\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2648\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2649\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2650\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2651\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgraphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmpty\u001b[49m\n\u001b[32m   2652\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2653\u001b[39m loop.after_tick()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Gen-Agentic-AI-Tutorials\\.venv\\Lib\\site-packages\\langgraph\\pregel\\_runner.py:167\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    165\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    166\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    181\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Gen-Agentic-AI-Tutorials\\.venv\\Lib\\site-packages\\langgraph\\pregel\\_retry.py:42\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     40\u001b[39m     task.writes.clear()\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     44\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Gen-Agentic-AI-Tutorials\\.venv\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py:656\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    654\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    655\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m656\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    657\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    658\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Gen-Agentic-AI-Tutorials\\.venv\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py:400\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    398\u001b[39m         run_manager.on_chain_end(ret)\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m400\u001b[39m     ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[103]\u001b[39m\u001b[32m, line 8\u001b[39m, in \u001b[36mSummarizationMiddleware\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m      6\u001b[39m     summary_prompt = \u001b[33m\"\u001b[39m\u001b[33mSummarize the following conversation into one conversation: \u001b[39m\u001b[38;5;132;01m{messages}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m      7\u001b[39m     summary = llm.invoke(summary_prompt.format(messages=all_messages))\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     summarized_messages = [\u001b[43mHumanMessage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m=\u001b[49m\u001b[43msummary\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[32m     10\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m { \u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: summarized_messages }\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m messages\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Gen-Agentic-AI-Tutorials\\.venv\\Lib\\site-packages\\langchain_core\\messages\\human.py:60\u001b[39m, in \u001b[36mHumanMessage.__init__\u001b[39m\u001b[34m(self, content, content_blocks, **kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(\n\u001b[32m     56\u001b[39m         content=cast(\u001b[33m\"\u001b[39m\u001b[33mstr | list[str | dict]\u001b[39m\u001b[33m\"\u001b[39m, content_blocks),\n\u001b[32m     57\u001b[39m         **kwargs,\n\u001b[32m     58\u001b[39m     )\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Gen-Agentic-AI-Tutorials\\.venv\\Lib\\site-packages\\langchain_core\\messages\\base.py:179\u001b[39m, in \u001b[36mBaseMessage.__init__\u001b[39m\u001b[34m(self, content, content_blocks, **kwargs)\u001b[39m\n\u001b[32m    177\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(content=content_blocks, **kwargs)\n\u001b[32m    178\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m179\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Gen-Agentic-AI-Tutorials\\.venv\\Lib\\site-packages\\langchain_core\\load\\serializable.py:116\u001b[39m, in \u001b[36mSerializable.__init__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args: Any, **kwargs: Any) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    115\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: D419  # Intentional blank docstring\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Gen-Agentic-AI-Tutorials\\.venv\\Lib\\site-packages\\pydantic\\main.py:250\u001b[39m, in \u001b[36mBaseModel.__init__\u001b[39m\u001b[34m(self, **data)\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[32m    249\u001b[39m __tracebackhide__ = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m validated_self = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[32m    252\u001b[39m     warnings.warn(\n\u001b[32m    253\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m    254\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    255\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    256\u001b[39m         stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m    257\u001b[39m     )\n",
      "\u001b[31mValidationError\u001b[39m: 19 validation errors for HumanMessage\ncontent.str\n  Input should be a valid string [type=string_type, input_value=AIMessage(content='', add...: 0, 'reasoning': 512}}), input_type=AIMessage]\n    For further information visit https://errors.pydantic.dev/2.12/v/string_type\ncontent.list[union[str,dict[any,any]]].0.str\n  Input should be a valid string [type=string_type, input_value=('content', ''), input_type=tuple]\n    For further information visit https://errors.pydantic.dev/2.12/v/string_type\ncontent.list[union[str,dict[any,any]]].0.dict[any,any]\n  Input should be a valid dictionary [type=dict_type, input_value=('content', ''), input_type=tuple]\n    For further information visit https://errors.pydantic.dev/2.12/v/dict_type\ncontent.list[union[str,dict[any,any]]].1.str\n  Input should be a valid string [type=string_type, input_value=('additional_kwargs', {'refusal': None}), input_type=tuple]\n    For further information visit https://errors.pydantic.dev/2.12/v/string_type\ncontent.list[union[str,dict[any,any]]].1.dict[any,any]\n  Input should be a valid dictionary [type=dict_type, input_value=('additional_kwargs', {'refusal': None}), input_type=tuple]\n    For further information visit https://errors.pydantic.dev/2.12/v/dict_type\ncontent.list[union[str,dict[any,any]]].2.str\n  Input should be a valid string [type=string_type, input_value=('response_metadata', {'t...gth', 'logprobs': None}), input_type=tuple]\n    For further information visit https://errors.pydantic.dev/2.12/v/string_type\ncontent.list[union[str,dict[any,any]]].2.dict[any,any]\n  Input should be a valid dictionary [type=dict_type, input_value=('response_metadata', {'t...gth', 'logprobs': None}), input_type=tuple]\n    For further information visit https://errors.pydantic.dev/2.12/v/dict_type\ncontent.list[union[str,dict[any,any]]].3.str\n  Input should be a valid string [type=string_type, input_value=('type', 'ai'), input_type=tuple]\n    For further information visit https://errors.pydantic.dev/2.12/v/string_type\ncontent.list[union[str,dict[any,any]]].3.dict[any,any]\n  Input should be a valid dictionary [type=dict_type, input_value=('type', 'ai'), input_type=tuple]\n    For further information visit https://errors.pydantic.dev/2.12/v/dict_type\ncontent.list[union[str,dict[any,any]]].4.str\n  Input should be a valid string [type=string_type, input_value=('name', None), input_type=tuple]\n    For further information visit https://errors.pydantic.dev/2.12/v/string_type\ncontent.list[union[str,dict[any,any]]].4.dict[any,any]\n  Input should be a valid dictionary [type=dict_type, input_value=('name', None), input_type=tuple]\n    For further information visit https://errors.pydantic.dev/2.12/v/dict_type\ncontent.list[union[str,dict[any,any]]].5.str\n  Input should be a valid string [type=string_type, input_value=('id', 'lc_run--019b46b1-...61-89a9-f1f0a69e4038-0'), input_type=tuple]\n    For further information visit https://errors.pydantic.dev/2.12/v/string_type\ncontent.list[union[str,dict[any,any]]].5.dict[any,any]\n  Input should be a valid dictionary [type=dict_type, input_value=('id', 'lc_run--019b46b1-...61-89a9-f1f0a69e4038-0'), input_type=tuple]\n    For further information visit https://errors.pydantic.dev/2.12/v/dict_type\ncontent.list[union[str,dict[any,any]]].6.str\n  Input should be a valid string [type=string_type, input_value=('tool_calls', []), input_type=tuple]\n    For further information visit https://errors.pydantic.dev/2.12/v/string_type\ncontent.list[union[str,dict[any,any]]].6.dict[any,any]\n  Input should be a valid dictionary [type=dict_type, input_value=('tool_calls', []), input_type=tuple]\n    For further information visit https://errors.pydantic.dev/2.12/v/dict_type\ncontent.list[union[str,dict[any,any]]].7.str\n  Input should be a valid string [type=string_type, input_value=('invalid_tool_calls', []), input_type=tuple]\n    For further information visit https://errors.pydantic.dev/2.12/v/string_type\ncontent.list[union[str,dict[any,any]]].7.dict[any,any]\n  Input should be a valid dictionary [type=dict_type, input_value=('invalid_tool_calls', []), input_type=tuple]\n    For further information visit https://errors.pydantic.dev/2.12/v/dict_type\ncontent.list[union[str,dict[any,any]]].8.str\n  Input should be a valid string [type=string_type, input_value=('usage_metadata', {'inpu...: 0, 'reasoning': 512}}), input_type=tuple]\n    For further information visit https://errors.pydantic.dev/2.12/v/string_type\ncontent.list[union[str,dict[any,any]]].8.dict[any,any]\n  Input should be a valid dictionary [type=dict_type, input_value=('usage_metadata', {'inpu...: 0, 'reasoning': 512}}), input_type=tuple]\n    For further information visit https://errors.pydantic.dev/2.12/v/dict_type",
      "During task with name 'SummarizationMiddleware' and id 'b81af0aa-df22-a86b-93b6-754d7db84e73'"
     ]
    }
   ],
   "source": [
    "test_messages = [\n",
    "    HumanMessage(content=\"Check my device status\"),\n",
    "    AIMessage(\n",
    "        content=\"Running diagnostics...\",\n",
    "        tool_calls=[{\n",
    "            \"id\": \"diag_1\",\n",
    "            \"name\": \"run_diagnostic\",\n",
    "            \"args\": {}\n",
    "        }]\n",
    "    ),\n",
    "    ToolMessage(\n",
    "        content=\"temp=42C voltage=2.9v status=normal\",\n",
    "        tool_call_id=\"diag_1\"\n",
    "    ),\n",
    "    HumanMessage(content=\"Is 42C normal?\"),\n",
    "    AIMessage(content=\"Yes, 42C is safe for most devices.\"),\n",
    "    HumanMessage(content=\"What about 80C?\"),\n",
    "    HumanMessage(content=\"And what if it's not turning on?\"),\n",
    "    HumanMessage(content=\"Also check battery level\"),\n",
    "]\n",
    "\n",
    "# Now invoke — should work!\n",
    "response = workflow.invoke(\n",
    "    {\"messages\": test_messages},\n",
    "    {\"configurable\": {\"thread_id\": \"test1\"}}\n",
    ")\n",
    "\n",
    "print(response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "7e84be38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Check my device status', additional_kwargs={}, response_metadata={}, id='b6022d2d-d650-4e99-8af6-ca3884a1eeff'),\n",
       "  AIMessage(content='Running diagnostics...', additional_kwargs={}, response_metadata={}, id='78b8fa42-9575-4b99-8718-ba98caed274e', tool_calls=[{'name': 'run_diagnostic', 'args': {}, 'id': 'diag_1', 'type': 'tool_call'}]),\n",
       "  ToolMessage(content='temp=42C voltage=2.9v status=normal', id='1e12a35a-69f2-474e-b1fd-c5c48cd96e17', tool_call_id='diag_1'),\n",
       "  HumanMessage(content='Is 42C normal?', additional_kwargs={}, response_metadata={}, id='60ab9352-7ce5-46b4-873a-ce9feca9c9d9'),\n",
       "  AIMessage(content='Yes, 42C is safe for most devices.', additional_kwargs={}, response_metadata={}, id='46b9fd4d-67ba-4556-93ff-be83c4564a93'),\n",
       "  HumanMessage(content='What about 80C?', additional_kwargs={}, response_metadata={}, id='1a0b7025-494f-4724-8093-94dd65125217'),\n",
       "  HumanMessage(content=\"And what if it's not turning on?\", additional_kwargs={}, response_metadata={}, id='54e8311e-694d-4ec5-ba50-8a786b228118'),\n",
       "  HumanMessage(content='Also check battery level', additional_kwargs={}, response_metadata={}, id='edf0b3a4-068a-4ab3-a9ed-25119440de98'),\n",
       "  SystemMessage(content='Conversation summary: The user requested a status check on their device, receiving confirmation that it was normal with a temperature of 42°C, which the AI deemed safe. The user then inquired about the safety of 80°C and the possibility of the device not turning on.', additional_kwargs={}, response_metadata={}, id='c3a1d26a-a0ef-457e-8bd1-097b709580fa'),\n",
       "  AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 512, 'prompt_tokens': 175, 'total_tokens': 687, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 512, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-Cpc8WeTLCWY32ulPHQJ4nP2FHLVk9', 'service_tier': 'default', 'finish_reason': 'length', 'logprobs': None}, id='lc_run--019b46ad-e696-7b41-a30d-0309dce5ec62-0', usage_metadata={'input_tokens': 175, 'output_tokens': 512, 'total_tokens': 687, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 512}})]}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a6f35393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9067124d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The temperature of my device is 42C. What should I do?',\n",
       " \"My device won't turn on. What should I do?\",\n",
       " 'Is the device plugged in and turned on?',\n",
       " \"Yes, it's plugged in and turned on.\",\n",
       " 'Is the device showing any lights or indicators?',\n",
       " \"What's the temperature of the device?\",\n",
       " 'If you’re referring to the same reading you mentioned earlier, the temperature is 42°C. That’s warm but not usually dangerous by itself. If the device won’t turn on, overheating could have triggered a protective shutdown, or there could be another issue.\\n\\nWhat you can do now:\\n- Power down and unplug the device. If possible, remove the battery and let it cool for 15–30 minutes in a well-ventilated area.\\n- Check vents and fans. Look for dust blocking the intake/exhaust and gently clean with compressed air if you can.\\n- Make sure the device has good airflow. Don’t use it on a bed, couch, or any soft surface.\\n- After it’s cooled, try turning it on again. If it still won’t start, try a power cycle: hold the power button for 15–20 seconds, then reconnect power and turn on.\\n- If you can boot, monitor temps with software (examples: HWMonitor/Core Temp on Windows, iStat Menus or Macs Fan Control on macOS, or lm-sensors on Linux). Look for sustained high temps or fans not spinning.\\n- Check running software for high CPU/GPU load. End unnecessary tasks and update drivers/BIOS/firmware.\\n- Consider a cooling aid (cooling pad, better room ventilation) and ensure the environment is cool.\\n- If temps stay high or the device still won’t turn on after cooling, there may be a hardware issue (fan failure, thermal paste, battery, motherboard). Contact support or a repair service, especially if it’s under warranty.\\n\\nIf you can tell me the device type (laptop/desktop/phone/tablet) and the OS, I can tailor exact steps and any specific software to use. Also, can you confirm whether the 42°C reading is current or from a prior measurement?',\n",
       " 'The temperature of my device is 42C. What should I do?',\n",
       " \"My device won't turn on. What should I do?\",\n",
       " 'Is the device plugged in and turned on?',\n",
       " \"Yes, it's plugged in and turned on.\",\n",
       " 'Is the device showing any lights or indicators?',\n",
       " \"What's the temperature of the device?\",\n",
       " 'The temperature is 42°C.\\n\\nSince it won’t turn on, overheating could have triggered a protective shutdown or there may be another issue. Try these steps:\\n\\n- Power down and unplug the device. If possible, remove the battery and let it cool for 15–30 minutes in a well-ventilated area.\\n- Check vents and fans for dust. Clean gently with compressed air if you can.\\n- After it’s cooled, try a power cycle: hold the power button for 15–20 seconds, then reconnect power and try to turn it on.\\n- If you can boot, monitor temps with appropriate software (Windows: HWMonitor/Core Temp; macOS: Macs Fan Control or iStat Menus; Linux: lm-sensors). Look for sustained high temps or a non-spinning fan.\\n- Check for high CPU/GPU load or background processes that could cause overheating. Update drivers/BIOS/firmware as needed.\\n- Ensure good airflow in the environment (no soft surfaces, vents not blocked, ambient room not too hot). Consider a cooling pad if it’s a laptop.\\n- If temps stay high after cooling or it still won’t power on, there may be a hardware issue (fan failure, degraded thermal paste, battery, motherboard). Contact support or a repair service, especially if it’s under warranty.\\n\\nIf you can share your device type (laptop/desktop/phone/tablet) and OS, I can give more exact, step-by-step guidance. Also, is that 42°C the current reading and where is it measured (CPU core, GPU, or system sensor)?']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f36e518",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentic-ai-tutorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
